{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b122f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mindhive/nklab5/users/amarvi/anaconda3/envs/fb-dino/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import utils\n",
    "import vision_transformer as vits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e57b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take key student in provided checkpoint dict\n",
      "Pretrained weights found at /om2/user/amarvi/dino/saved_models/face400_dino/checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n",
      "Model vit_small built.\n"
     ]
    }
   ],
   "source": [
    "arch = 'vit_small'\n",
    "patches = 16\n",
    "dat = 'face'\n",
    "ckpt_pth = f'/om2/user/amarvi/dino/saved_models/{dat}400_dino/checkpoint.pth'\n",
    "\n",
    "\n",
    "# load in model\n",
    "model = vits.__dict__[arch](patch_size=patches, num_classes=0)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "utils.load_pretrained_weights(model, ckpt_pth, 'student', arch, patches)\n",
    "\n",
    "print(f\"Model {arch} built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73ee1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=3),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d21c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 200.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# cols = ['model', 'dataset', 'size', 'image_idx', 'activation']\n",
    "# df = pd.DataFrame(columns=cols)\n",
    "\n",
    "img_folder = f'/om2/user/amarvi/FACE/data/behav_{dat}'\n",
    "img_list = []\n",
    "\n",
    "for jpg_name in tqdm(os.listdir(img_folder)):\n",
    "    img_pth = os.path.join(img_folder, jpg_name)\n",
    "    img = Image.open(img_pth).convert('RGB')\n",
    "    inpt_img = transform(img)\n",
    "    img_list.append(inpt_img)\n",
    "\n",
    "# Stack all images into a single batch tensor\n",
    "batch_tensor = torch.stack(img_list).cuda()    \n",
    "out = model.get_intermediate_layers(batch_tensor,n=12)\n",
    "\n",
    "for idx, layer_activation in enumerate(out):\n",
    "    clss_token = layer_activation[:, 0, :].squeeze()\n",
    "    clss_token = clss_token.detach().cpu().numpy()\n",
    "    df.loc[len(df)] = {'model': 'dino', 'dataset': dat, 'size': '400', 'image_idx': idx+1, 'activation': clss_token}\n",
    "    \n",
    "# df.to_pickle('/om2/user/amarvi/dino/saved_models/mts_dino_activations.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2701905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1560) (1, 1560)\n"
     ]
    }
   ],
   "source": [
    "f = scipy.io.loadmat('/om2/user/amarvi/FACE/data/data_up.mat')\n",
    "\n",
    "triplet = f['data_up'][0][0][0]\n",
    "perf = f['data_up'][0][0][1]\n",
    "\n",
    "print(triplet.shape, perf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faa2f219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:06,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "column_names = ['model', 'size', 'dataset', 'layer', 'results', 'accuracy', 'ci']\n",
    "res_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    act = row['activation']\n",
    "    dat = row['dataset']\n",
    "    count = 0\n",
    "    bstrap = []\n",
    "\n",
    "    for idx, trio in enumerate(triplet.transpose()):\n",
    "        trio = trio-1\n",
    "        gt = trio//5\n",
    "        [targ, m1, m2] = trio\n",
    "\n",
    "        dist1 = np.linalg.norm(act[targ] - act[m1])\n",
    "        dist2 = np.linalg.norm(act[targ] - act[m2])\n",
    "        model_choice = np.argmax(np.array([dist1, dist2])) + 1\n",
    "        correct_choice = np.where(gt != gt[0])[0]\n",
    "\n",
    "\n",
    "        bstrap.append(int(model_choice == correct_choice))\n",
    "        if model_choice != correct_choice:\n",
    "            count += 1\n",
    "            \n",
    "    bstrap = np.array(bstrap)\n",
    "    n_bootstrap = 10000\n",
    "    bootstrap_samples = np.random.choice(bstrap, size=(len(bstrap), n_bootstrap), replace=True)\n",
    "    bootstrap_sample_means = np.mean(bootstrap_samples, axis=0)\n",
    "\n",
    "    ci_lower = np.percentile(bootstrap_sample_means, 2.5)\n",
    "    ci_upper = np.percentile(bootstrap_sample_means, 97.5)\n",
    "\n",
    "\n",
    "    acc = 1 - count/len(triplet[0])\n",
    "#     print(\"CI:\", (ci_lower, ci_upper), 'Mean:', np.mean(bstrap))\n",
    "#     print(dat, index, acc)\n",
    "\n",
    "    res_df.loc[len(res_df)] = {'model': 'dino', 'size': '400', 'dataset': dat, 'layer': index%12+1, 'results': bstrap, 'accuracy':np.mean(bstrap), 'ci': (ci_lower, ci_upper)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "282b7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_pickle('/om2/user/amarvi/dino/saved_models/mts_dino_results.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
